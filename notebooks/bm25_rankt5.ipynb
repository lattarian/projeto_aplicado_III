{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üéì Sistema de Recomenda√ß√£o de Cursos da Udemy com BM25 e RankT5\n",
    "\n",
    "Este projeto prop√µe um sistema h√≠brido de recomenda√ß√£o de cursos online, combinando t√©cnicas de recupera√ß√£o de informa√ß√£o com aprendizado supervisionado. A abordagem utiliza:\n",
    "\n",
    "- üîç BM25 para recupera√ß√£o inicial baseada em similaridade textual\n",
    "- üß† RankT5 (modelo baseado em T5) para reranqueamento supervisionado com entendimento sem√¢ntico\n",
    "\n",
    "O objetivo √© recomendar cursos mais relevantes com base apenas no t√≠tulo da consulta, simulando um cen√°rio com informa√ß√µes limitadas, como em buscas r√°pidas feitas por usu√°rios em plataformas educacionais como a Udemy.\n"
   ],
   "id": "483f4eeaf8e83bc6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. üõ†Ô∏è Configura√ß√£o do NLTK e Stop Words\n",
    "\n",
    "Nesta etapa inicial, realizamos a prepara√ß√£o do ambiente de processamento de linguagem natural com a biblioteca NLTK. \n",
    "\n",
    "Foram baixados os recursos essenciais:\n",
    "- Tokenizador `punkt` (para dividir textos em palavras)\n",
    "- Lista de `stopwords` (palavras comuns que n√£o carregam muito significado)\n",
    "\n",
    "Al√©m das stopwords padr√£o da l√≠ngua inglesa, foram adicionadas **stopwords espec√≠ficas do dom√≠nio de cursos de tecnologia**, como \"course\", \"tutorial\", \"beginner\", \"bootcamp\", entre outras. Isso garante que o modelo se concentre em termos realmente informativos, como linguagens de programa√ß√£o, tecnologias e temas de conte√∫do.\n",
    "\n",
    "Essa filtragem √© aplicada durante a tokeniza√ß√£o dos t√≠tulos dos cursos, melhorando a qualidade da entrada para o c√°lculo de similaridade com BM25."
   ],
   "id": "22fdab22ac895954"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "656362ec7c8963b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:58:52.538956Z",
     "start_time": "2025-04-07T12:58:52.508841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import contextlib\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define um diret√≥rio local no projeto\n",
    "nltk_data_dir = os.path.join(os.getcwd(), \"nltk_data\")\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "\n",
    "nltk.data.path = [nltk_data_dir]  \n",
    "\n",
    "with open(os.devnull, 'w') as fnull:\n",
    "    with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n",
    "        nltk.download(\"punkt_tab\", download_dir=nltk_data_dir)\n",
    "        nltk.download(\"stopwords\", download_dir=nltk_data_dir)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "extra_stops = {\n",
    "    \"learn\", \"learning\", \"course\", \"courses\", \"tutorial\", \"introduction\", \"intro\",\n",
    "    \"guide\", \"complete\", \"bootcamp\", \"beginner\", \"beginners\", \"masterclass\", \"hands-on\",\n",
    "    \"project\", \"projects\", \"practical\", \"training\", \"zero\", \"hero\", \"step\", \"steps\",\n",
    "    \"certification\", \"exam\", \"pass\", \"skills\", \"foundation\", \"foundations\", \"build\",\n",
    "    \"create\", \"develop\", \"start\", \"basic\", \"advance\", \"advanced\", \"series\", \"crash\",\n",
    "    \"overview\", \"from\", \"scratch\", \"professional\", \"essentials\"\n",
    "}\n",
    "\n",
    "custom_stopwords = stop_words.union(extra_stops)\n",
    "\n",
    "def tokenize_course_title(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [word for word in tokens if word.isalnum() and word not in custom_stopwords]\n"
   ],
   "id": "efd098e2891dc4c5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/luattarian/Documen\n",
      "[nltk_data]     ts/GitHub/projeto_aplicado_III/notebooks/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/luattarian/Documen\n",
      "[nltk_data]     ts/GitHub/projeto_aplicado_III/notebooks/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. üì• Importa√ß√£o dos Dados\n",
    "\n",
    "Nesta etapa, importamos os dados brutos que servir√£o como base para o sistema de recomenda√ß√£o. Os dados consistem em um arquivo CSV contendo aproximadamente 22 mil t√≠tulos de cursos da categoria \"IT & Software\" da plataforma Udemy, extra√≠do da base p√∫blica do Kaggle.\n",
    "\n",
    "Apenas o campo de t√≠tulo √© utilizado, o que simula um cen√°rio desafiador, onde o sistema precisa fazer recomenda√ß√µes sem contar com descri√ß√µes detalhadas, avalia√ß√µes de usu√°rios ou outras informa√ß√µes adicionais.\n",
    "\n",
    "Esses t√≠tulos ser√£o utilizados para:\n",
    "- Construir o √≠ndice BM25 para recupera√ß√£o inicial\n",
    "- Gerar pares positivos e negativos para o treinamento supervisionado do RankT5\n"
   ],
   "id": "26e327c7be5d3bbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:58:52.629085Z",
     "start_time": "2025-04-07T12:58:52.546247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"üìÇ Carregando cursos da base Udemy...\")\n",
    "df = pd.read_csv(\"../data/udemy_output_All_IT__Software_p1_p626.csv\")\n",
    "titles = df[\"title\"].dropna().drop_duplicates().tolist()"
   ],
   "id": "26b34da1c455c90c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Carregando cursos da base Udemy...\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. üîó Gera√ß√£o de Dados para Treinamento do RankT5\n",
    "\n",
    "Nesta etapa, constru√≠mos a base supervisionada necess√°ria para treinar o modelo RankT5. Para isso, utilizamos o algoritmo BM25 para medir a similaridade entre os t√≠tulos dos cursos da base da Udemy.\n",
    "\n",
    "Para cada curso (considerado como consulta), s√£o selecionados:\n",
    "- **3 pares positivos**: cursos mais semelhantes com base na pontua√ß√£o do BM25.\n",
    "- **3 pares negativos**: cursos com baixa similaridade (por exemplo, a partir do 50¬∫ resultado).\n",
    "\n",
    "Cada par √© ent√£o formatado como uma entrada textual no seguinte padr√£o:\n",
    "\n",
    "E recebe um r√≥tulo:\n",
    "- `\"1\"` se o par for considerado relevante (positivo)\n",
    "- `\"0\"` se o par for irrelevante (negativo)\n",
    "\n",
    "Esses exemplos textuais s√£o utilizados como entrada para o treinamento supervisionado do modelo RankT5, permitindo que ele aprenda a identificar a relev√¢ncia entre consultas e cursos com base no texto.\n",
    "\n"
   ],
   "id": "7e576a4f413567b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Tokenizar os t√≠tulos\n",
    "tokenized_titles = [tokenize_course_title(t) for t in titles]\n",
    "bm25 = BM25Okapi(tokenized_titles)\n",
    "\n",
    "print(\"Calculando matriz de similaridade BM25...\")\n",
    "bm25_matrix = np.array([bm25.get_scores(tokens) for tokens in tqdm(tokenized_titles)])\n",
    "\n",
    "print(\"Gerando pares com base nas similaridades BM25...\")\n",
    "pairs = []\n",
    "\n",
    "for i in tqdm(range(len(titles))):\n",
    "    scores = bm25_matrix[i]\n",
    "    sorted_indices = scores.argsort()[::-1]\n",
    "    sorted_indices = sorted_indices[sorted_indices != i]  # remove o pr√≥prio\n",
    "    \n",
    "    # Pares positivos (t√≠tulos similares) tres mais similares\n",
    "    positives = sorted_indices[:3]\n",
    "    # Pares negativos (t√≠tulos n√£o similares) tres aleat√≥rios com posi√ß√µes acima de 50 \n",
    "    negatives = random.sample(list(sorted_indices[50:]), 3) if len(sorted_indices) > 50 else sorted_indices[-3:]\n",
    "\n",
    "    for j in positives:\n",
    "        pairs.append((titles[i], titles[j], 1))\n",
    "    for j in negatives:\n",
    "        pairs.append((titles[i], titles[j], 0))\n",
    "\n",
    "# Salvar os pares no formato eperado pelo RankT5\n",
    "df_pairs = pd.DataFrame(pairs, columns=[\"query\", \"course\", \"label\"])\n",
    "df_pairs.to_csv(\"../data/bm25_pairs.csv\", index=False)\n",
    "\n",
    "print(\"Pares salvos em 'bm25_pairs.csv'\")"
   ],
   "id": "f38954760af84dcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. üìä Divis√£o dos Dados em Treino e Teste\n",
    "\n",
    "Antes de treinar o modelo RankT5, √© necess√°rio dividir os pares gerados em dois subconjuntos:\n",
    "\n",
    "- **Conjunto de treinamento (train):** utilizado para ajustar os pesos do modelo supervisionado.\n",
    "- **Conjunto de teste (test):** utilizado para avaliar a capacidade do modelo em generalizar para exemplos que ele nunca viu.\n",
    "\n"
   ],
   "id": "dbbef6ee9bca39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:02:14.826078Z",
     "start_time": "2025-04-06T22:38:15.840784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar os pares gerados anteriormente\n",
    "df = pd.read_csv(\"../data/bm25_pairs.csv\")\n",
    "\n",
    "# Formatar para RankT5\n",
    "df_rankt5 = pd.DataFrame({\n",
    "    \"input_text\": df.apply(lambda row: f\"Query: {row['query']} Course: {row['course']}\", axis=1),\n",
    "    \"label\": df[\"label\"].astype(str)\n",
    "})\n",
    "\n",
    "# Dividir treino e teste\n",
    "train_df, test_df = train_test_split(df_rankt5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Salvar os arquivos\n",
    "train_df.to_csv(\"../data/rankt5_train.csv\", index=False)\n",
    "test_df.to_csv(\"../data/rankt5_test.csv\", index=False)\n",
    "\n",
    "print(\"Arquivos salvos:\")\n",
    "print(\"rankt5_train.csv\")\n",
    "print(\"rankt5_test.csv\")"
   ],
   "id": "4fa165dcfa74951e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Arquivos salvos:\n",
      " - rankt5_train.csv\n",
      " - rankt5_test.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. üß† Treinamento do Modelo RankT5\n",
    "\n",
    "Com os dados supervisionados prontos (pares no formato \"Query: ... Course: ...\" com r√≥tulo 1 ou 0), iniciamos o treinamento do modelo RankT5.\n",
    "\n",
    "Utilizamos o modelo `t5-small` da biblioteca Hugging Face Transformers como base. Ele √© um modelo encoder-decoder, originalmente treinado com a abordagem \"texto para texto\", o que o torna ideal para tarefas como classifica√ß√£o, tradu√ß√£o, sumariza√ß√£o e, neste caso, reranqueamento supervisionado.\n",
    "\n",
    "Durante o treinamento:\n",
    "- O modelo recebe pares de entrada tokenizados com seus r√≥tulos correspondentes.\n",
    "- Aprende a prever se o curso √© ou n√£o relevante para a consulta.\n",
    "- √â ajustado por algumas √©pocas, utilizando o conjunto completo de dados.\n",
    "- A performance √© monitorada por meio da `validation_loss`, que indica a capacidade do modelo em generalizar para dados que n√£o viu.\n",
    "\n",
    "Esse processo transforma o T5 em um modelo capaz de entender rela√ß√µes sem√¢nticas entre consultas e t√≠tulos, indo al√©m da simples similaridade lexical capturada pelo BM25.\n"
   ],
   "id": "a2a5ae2db26c164b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:02:14.829466Z",
     "start_time": "2025-04-06T23:50:11.273204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# 1. Carregar e amostrar dados\n",
    "df = pd.read_csv(\"../data/rankt5_train.csv\")\n",
    "df_test = pd.read_csv(\"../data/rankt5_test.csv\")\n",
    "\n",
    "train_sample = df\n",
    "test_sample = df_test\n",
    "\n",
    "print(f\"üìö Dados de treino: {len(train_sample)}\")\n",
    "print(f\"üß™ Dados de teste: {len(test_sample)}\")\n",
    "\n",
    "# 2. Tokenizador e modelo\n",
    "model_name = \"t5-small\"\n",
    "print(\"‚úÇÔ∏è Tokenizando dados para entrada no modelo RankT5...\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# 3. Pr√©-processamento\n",
    "def preprocess(line):\n",
    "    input_text = str(line[\"input_text\"])\n",
    "    label_text = str(line[\"label\"])\n",
    "\n",
    "    input_enc = tokenizer(\n",
    "        input_text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=64\n",
    "    )\n",
    "    label_enc = tokenizer(\n",
    "        label_text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=4\n",
    "    )\n",
    "\n",
    "    input_enc[\"labels\"] = label_enc[\"input_ids\"]\n",
    "    return input_enc\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_sample).map(\n",
    "    preprocess, \n",
    "    remove_columns=train_sample.columns.tolist()\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_sample).map(\n",
    "    preprocess, \n",
    "    remove_columns=test_sample.columns.tolist()\n",
    ")\n",
    "\n",
    "# 4. Argumentos de treino\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../data/rankt5_output\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    ")\n",
    "\n",
    "# 5. Treinador\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "print(\"üöÄ Iniciando o treinamento supervisionado com RankT5...\")\n",
    "# 6. Treinar o modelo\n",
    "trainer.train()\n"
   ],
   "id": "eeab3ed3a414ac4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Dados de treino: 109200\n",
      "üß™ Dados de teste: 27300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 109200/109200 [00:14<00:00, 7293.29 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27300/27300 [00:03<00:00, 7358.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68250' max='68250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68250/68250 9:16:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.011707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.010036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.007768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.010586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.009637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=68250, training_loss=0.016236663949014678, metrics={'train_runtime': 33397.1507, 'train_samples_per_second': 16.349, 'train_steps_per_second': 2.044, 'total_flos': 9237077950464000.0, 'train_loss': 0.016236663949014678, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. ü§ù Fun√ß√£o de Recomenda√ß√£o H√≠brida com BM25 e RankT5\n",
    "\n",
    "Esta etapa implementa a l√≥gica final do sistema de recomenda√ß√£o, combinando a recupera√ß√£o inicial com BM25 e o reranqueamento supervisionado com RankT5.\n",
    "\n",
    "A fun√ß√£o h√≠brida opera em dois est√°gios:\n",
    "\n",
    "1. **üîç Recupera√ß√£o com BM25 (n√£o supervisionado)**  \n",
    "   Dada uma consulta (por exemplo, \"learn python for data science\"), o BM25 busca no corpus os cursos com t√≠tulos mais similares, com base na frequ√™ncia e distribui√ß√£o dos termos. Os **top-50 cursos mais similares** s√£o selecionados como candidatos iniciais.\n",
    "\n",
    "2. **üß† Reranqueamento com RankT5 (supervisionado)**  \n",
    "   Cada par (consulta + t√≠tulo do curso candidato) √© formatado como:  \n",
    "   Esses pares s√£o passados para o modelo RankT5, que retorna uma pontua√ß√£o de relev√¢ncia para cada curso. Os cursos s√£o ent√£o **reordenados de acordo com essas pontua√ß√µes**, priorizando aqueles que o modelo considera semanticamente mais relevantes.\n",
    "\n",
    "üîÅ O resultado final √© uma lista de recomenda√ß√µes ordenadas, que combina a efici√™ncia do BM25 com a capacidade sem√¢ntica do RankT5, entregando sugest√µes mais precisas e contextualizadas mesmo sem dados de intera√ß√£o do usu√°rio.\n",
    "\n",
    " "
   ],
   "id": "40f9fd7d62b6c11a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:03:06.524283Z",
     "start_time": "2025-04-07T13:03:04.679438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# === Carregar modelo RankT5 j√° treinado ===\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"../data/rankt5_output/checkpoint-68250\") \n",
    "\n",
    "tokenized_titles = [tokenize_course_title(t) for t in titles]\n",
    "bm25 = BM25Okapi(tokenized_titles)\n",
    "\n",
    "# === Fun√ß√£o principal de recomenda√ß√£o h√≠brida ===\n",
    "def recommend_courses(query, top_k=5):\n",
    "    query_tokens = tokenize_course_title(query)\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "    # Top-50 mais relevantes por BM25\n",
    "    top_50_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:50]\n",
    "    top_50_courses = [(titles[i], scores[i]) for i in top_50_indices]\n",
    "\n",
    "    # Criar pares para RankT5\n",
    "    input_pairs = [f\"Query: {query} Course: {course}\" for course, _ in top_50_courses]\n",
    "\n",
    "    # Infer√™ncia com RankT5\n",
    "    rankt5_scores = []\n",
    "    for text, (title, bm25_score) in zip(input_pairs, top_50_courses):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs)\n",
    "        prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        score = int(prediction) if prediction.isdigit() else 0\n",
    "        rankt5_scores.append((title, score, bm25_score))\n",
    "\n",
    "    # Ordenar pelo score do RankT5 e retornar Top-K\n",
    "    ranked = sorted(rankt5_scores, key=lambda x: (-x[1], -x[2]))  # primeiro pelo T5, depois BM25\n",
    "    return ranked[:top_k]\n",
    "\n",
    "def recommend_and_print(query, top_k=5):\n",
    "    recommendations = recommend_courses(query, top_k)\n",
    "    print(f\"\\nüéØ Recomenda√ß√£o para: '{query}'\\n\")\n",
    "    for i, (title, score, bm25_score) in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {title} (RankT5: {score}, BM25: {bm25_score:.2f})\")\n"
   ],
   "id": "953b512ceb7659ce",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7. üß™ Teste da Fun√ß√£o de Recomenda√ß√£o H√≠brida\n",
    "\n",
    "Nesta etapa, testamos o sistema de recomenda√ß√£o completo, combinando a recupera√ß√£o com BM25 e o reranqueamento com RankT5."
   ],
   "id": "1bcf8ee72f797120"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T14:42:29.854140Z",
     "start_time": "2025-04-07T14:42:28.190823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recommend_and_print(\"Python for beginners\")\n",
    "recommend_and_print(\"Java programming\")\n",
    "recommend_and_print(\"Machine learning with Python\")\n",
    "recommend_and_print(\"Web development with JavaScript\")\n",
    "recommend_and_print(\"Data science and analytics\")\n",
    "recommend_and_print(\"Cybersecurity\")\n"
   ],
   "id": "ab4ddca97ae9a171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Recomenda√ß√£o para: 'networking'\n",
      "\n",
      "1. Networking Fundamentals For All Networking Certification (RankT5: 1, BM25: 8.44)\n",
      "2. Networking Essentials (RankT5: 1, BM25: 8.09)\n",
      "3. IT Networking Fundamentals For Complete Beginners (RankT5: 1, BM25: 7.04)\n",
      "4. Learn the Fundamentals of Networking (RankT5: 1, BM25: 7.04)\n",
      "5. Introduction to Arista networking (RankT5: 1, BM25: 7.04)\n"
     ]
    }
   ],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
